[{"path":"index.html","id":"preface","chapter":"1 Preface","heading":"1 Preface","text":"notes first draft quite prelimenary. find errors, please let know emailing jwesten@iu.eduAn example code course available github repository https://github.com/r-introtodatascience/sample_repo.goal short courses give graduate students prelimenary introduction coding R. ‘instructor’ teach things may helpful, belief, coding, like math, learn . highly encourage following notes, play around code. Change things see changes output. think best way learn.next 5 ‘sessions’ looking county level unemployment data. goal provide examples descriptions commands techniques discovered useful working data. Specifically goal end sessions hope know :download data straight Rread data (Rda, csv, xlsx, dta)merge datasetssubset datasetscreate summary statistics plotsrun basic regressionsall paying particular attention file pathing teach export graphics tables R form can directly read LaTex (can easily read paper/presentation documents).example interactive plot can make package called plotly. Try interacting ! plot can select/deselect states want view. also link short post made using GIS R. show illustrate bit possible R familiarize basic functions.","code":""},{"path":"intro.html","id":"intro","chapter":"2 Introduction","heading":"2 Introduction","text":"goal section provide quick introduction refresher R. first time coding, brief introduction likely quite insufficient. encourage seek resources learn basics proceeding.particular cover:Writing LoopsString ManipulationProject OrganizationDownloading/Reading DataDownloading LoopIn lesson downloading cleaning data BLS county level employment statistics 1990-2019.","code":""},{"path":"intro.html","id":"very-basics","chapter":"2 Introduction","heading":"2.1 Very Basics","text":"assume R installed running. plenty guides online .Let’s first define arrays within R.can numeric based, case integer.Let’s dig going bit . telling R define vector, c( ) part, elements 1,2,3 give vector name . backwards arrow tells R name element defining.can make character based vectors well.can combine vectors dataframe (relevant start thinking reading /manipulating actual data). Since vectors length three, can easily create dataframe (think matrix) column names name vectors, rows elements vectors.Now first_dataframe going similar format typically read data excel files R. can access certain rows columns within dataframe putting square brackets name dataframe. example wanted print element first row first column, define variable x print x. (Keep mind ordering rows, columns)wanted print elements first row, just leave column (comma) blank:1st & 3rd row?Another way define another variable, say y vector elements 1 3. Notice output .can thing columns (need remember order square brackets rows, columns). Note: put negative sign front commands brackets, instead “keeping” certain rows columns, means remove! command -3, saying REMOVE column 3!third column named C, can also pull column referencing ’s name dollar sign, :may sound useful now, think many columns variables, say wage, hoursworked, fulltime, hundreds . don’t want find column number hoursworked , can just reference column name.","code":"numvec1<-c(5,6,7)  # 1\nnumvec2<-c(7,8,9)  # 2charvec1<-c(\"a\", \"b\", \"c\")  # 1\ncharvec2<-c(\"d\", \"e\", \"f\")  # 2first_dataframe<-data.frame(numvec1,numvec2,charvec1,charvec2)  # 1\nprint(first_dataframe)                                          # 2##   numvec1 numvec2 charvec1 charvec2\n## 1       5       7        a        d\n## 2       6       8        b        e\n## 3       7       9        c        fx<-first_dataframe[1,1]  # 1\nprint(x)                 # 2## [1] 5x<-first_dataframe[1,]  # 1\nprint(x)                # 2##   numvec1 numvec2 charvec1 charvec2\n## 1       5       7        a        dx<-first_dataframe[c(1,3),]  # 1\nprint(x)                     # 2##   numvec1 numvec2 charvec1 charvec2\n## 1       5       7        a        d\n## 3       7       9        c        fy<-c(1,3)               # 1\nx<-first_dataframe[y,]  # 2\nprint(x)                # 3##   numvec1 numvec2 charvec1 charvec2\n## 1       5       7        a        d\n## 3       7       9        c        fx<-first_dataframe[,3]   # 1\ny<-first_dataframe[,-3]  # 2\nprint(x)                 # 3## [1] \"a\" \"b\" \"c\"print(y)  # 1##   numvec1 numvec2 charvec2\n## 1       5       7        d\n## 2       6       8        e\n## 3       7       9        fx<-first_dataframe$charvec1  # 1\nprint(x)                     # 2## [1] \"a\" \"b\" \"c\""},{"path":"intro.html","id":"and-and-or-operators","chapter":"2 Introduction","heading":"2.1.0.1 “And” and “Or” Operators","text":"couple common operators may want use “” “” statements. Within R:“&” : “” operator“|” : “” operatorFor example:","code":"\nfirst_dataframe[first_dataframe$numvec1>=6 & first_dataframe$numvec2<9,]  # 1##   numvec1 numvec2 charvec1 charvec2\n## 2       6       8        b        e\nfirst_dataframe[first_dataframe$numvec1>=6 | first_dataframe$numvec2<9,]  # 1##   numvec1 numvec2 charvec1 charvec2\n## 1       5       7        a        d\n## 2       6       8        b        e\n## 3       7       9        c        f"},{"path":"intro.html","id":"writing-loops","chapter":"2 Introduction","heading":"2.2 Writing Loops","text":"Going line line:Line 1: Define vector letters.Line 2: Report number elements letter vector save letters_lLine 3: Defining loop. index , run 0 however long letters vector (try adding letters!) Note loop action defined within curly braces.Line 4: every defined Line 3 want print corresponding element vector letters.Okay, great. help us reading data? ’ll get next section.","code":"letters<-c(\"a\", \"b\", \"c\", \"d\", \"e\")  # 1\nletters_l<-length(letters)           # 2\nfor (i in 1:letters_l){              # 3\n  print(letters[i])                  # 4\n}                                    # 5## [1] \"a\"\n## [1] \"b\"\n## [1] \"c\"\n## [1] \"d\"\n## [1] \"e\""},{"path":"intro.html","id":"string-manipulation","chapter":"2 Introduction","heading":"2.3 String Manipulation","text":"","code":""},{"path":"intro.html","id":"string-concatenation","chapter":"2 Introduction","heading":"2.3.1 String Concatenation","text":"Notice define b strings. paste paste0 combine strings one string. can see paste places space two strings paste0 . paste0 comes quite handy working file pathing see. Yes ’s easy!using project may useful know can concatenate two vectors strings well.","code":"\na<-\"This is a the start\"  # 1\nb<-\"of a sentence\"        # 2\nprint(paste0(a,b))        # 3## [1] \"This is a the startof a sentence\"\nprint(paste(a,b))  # 1## [1] \"This is a the start of a sentence\"\na<-c(\"This is a the start\", \"Now we have\", \"This really is\", \"Economics is\")  # 1\nb<-c(\"of a sentence.\", \"another sentence.\", \"quite handy.\", \"awesome!\")       # 2\nprint(paste(a,b))                                                             # 3## [1] \"This is a the start of a sentence.\" \"Now we have another sentence.\"     \n## [3] \"This really is quite handy.\"        \"Economics is awesome!\""},{"path":"intro.html","id":"string-padding","chapter":"2 Introduction","heading":"2.3.2 String Padding","text":"Consider vector numbers currently runs 1-19. Now need ‘single character’ digits leading zero. instead “1” need “01.”use paste0 combine 0 vector.don’t want leading 0 front double ‘character’ digits (ie DON’T want “090”). break vector single character digits two character digits, manipulate single character digits, combine back double character digits. easier way: str_pad !Now looks like want! str_pad ? str_pad telling stringr want elements numbvec length 2. stringr checks see elements less 2 characters, element adds “0”’s left side reaches length 2. already length 2, leave alone.many handy commands deal strings R. just couple commands using. writing post handy functions coming weeks link .","code":"\nnumbvec<-as.character(1:19)  # 1\nprint(paste0(\"0\", numbvec))  # 2##  [1] \"01\"  \"02\"  \"03\"  \"04\"  \"05\"  \"06\"  \"07\"  \"08\"  \"09\"  \"010\" \"011\" \"012\" \"013\"\n## [14] \"014\" \"015\" \"016\" \"017\" \"018\" \"019\"\nrequire(stringr)                           # 1\nnumbvec<-as.character(1:19)                # 2\nprint(str_pad(numbvec, 2, \"left\", \"0\")  )  # 3##  [1] \"01\" \"02\" \"03\" \"04\" \"05\" \"06\" \"07\" \"08\" \"09\" \"10\" \"11\" \"12\" \"13\" \"14\" \"15\" \"16\"\n## [17] \"17\" \"18\" \"19\""},{"path":"intro.html","id":"project-organization","chapter":"2 Introduction","heading":"2.4 Project Organization","text":"get started, let’s set folder project create subfolders keep things organized. project recommend following subfolders, good minimum organizing project:raw_data: put `preprocessed’ data getting MIT Election Lab.scripts: save R-scripts folderprocessed_data: want save intermediate data steps raw data output.tables: tex tables generate save folderfigures: figures generate save foldertex: can paper /presentationsYou can make folders feel keeps organized. main point want make well worth time think want organize project. Oftentimes jump right without plan, things become jumbled mess. (want go organization strategies, recommend looking waf, specifically check Templates Reproducible Research Projects Economics.)project folder now looks like :","code":""},{"path":"intro.html","id":"first-r-script","chapter":"2 Introduction","heading":"2.4.1 First R script!","text":"Now folders created, let’s now create paths folders R. Let’s start creating variable workingdir can define path main folder.Now going create script, let’s save workingdir.R place main parent folder. going using path defined script create paths folders.Now top scripts can :Now says variable named workingdir points main parent folder. script define paths folders. front scripts, can easily reference create easier pathing .","code":"\nworkingdir<-\"PATH_TO_YOUR_WORKING_DIR\"  # 1\nfolder_figures<-paste0(workingdir, \"figures\")                # 1\nfolder_processed_data<-paste0(workingdir, \"processed_data\")  # 2\nfolder_raw_data<-paste0(workingdir, \"raw_data\")              # 3\nfolder_scripts<-paste0(workingdir, \"scripts\")                # 4\nfolder_tables<-paste0(workingdir, \"tables\")                  # 5\nfolder_tex<-paste0(workingdir, \"tex\")                        # 6\nworkingdir<-\"PATH_TO_YOUR_WORKING_DIR\"    # 1\nsource(paste0(workingdir, workingdir.r))  # 2"},{"path":"intro.html","id":"downloading-within-r","chapter":"2 Introduction","heading":"2.5 Downloading within R","text":"can use R direct link download. first argument download.file() command takes use url xslx document second argument destination saved. last argument basically telling R excel docs plain text. (Don’t forget workingdir defined Project Organization","code":"\ndownload.file(\"https://www.bls.gov/lau/laucnty90.xlsx\",     # 1\n  paste0(folder_raw_data, \"bls_unemp_90.xlsx\"), mode=\"wb\")  # 2"},{"path":"intro.html","id":"reading-in-data","chapter":"2 Introduction","heading":"2.6 Reading in Data","text":"read data R, let’s see dealing . Opening file excel can see issues reading file .can notice first row file title spread across columns :J. Variable names spread across anywhere 1-3 rows. lastly empty column F. bright side observe year’s files, exact structure. Hence able use loop eventually clean instead one time.main package using readxl, quite self explanatory. package meant help read excel docs. Let’s try open file 1990 downloaded R. can R Studio’s functionality.Within “Environment” area R Studio, click Import Dataset, Excel…definitely multiple ways , can see options available. first deselect “First Row Names” (option nice data already precleaned form first row simply variable names.) begin skip rows, 5 rows skipping leads first row first row data.Next can handle column F noticed blank. column 6 stays consistent across years (can check ). Remembering lessons Basics section can subset dataframe removing column 6.Hence something look like following command script.last line giving columns names based names saw excel document.can observe data frame ssee ’s fully cleaned. first seems (actually initially thought ). However reading data, grabbed 2 extra rows end file. Hence 2 rows end data frame NA’s. Let’s drop two rows, can use command .na prior include “!” saying ‘.na.’good place pause want challenge. tools needed write loop download files 1990-2019.","code":"\nrequire(readxl)                                                                           # 1\nworkingdir<-\"C:/Users/weste/Documents/GitHub/r-introtodatascience/sample_repo/\"           # 2\nbls_unemp_90 <- read_excel(paste0(folder_raw_data, \"/bls_unemp_90.xlsx\"),                 # 3\n                           col_names=FALSE, skip=5)                                       # 4\nbls_unemp_90<-bls_unemp_90[,-6]                                                           # 5\ncolnames(bls_unemp_90)<-c(\"LAUS_code\", \"State_fips\", \"County_fips\", \"County_name\",        # 6\n                          \"Year\", \"Labor_force\", \"Employed\", \"Unemployed\", \"Unemp_rate\")  # 7\nbls_unemp_90<-bls_unemp_90[!is.na(bls_unemp_90$State_fips),]  # 1"},{"path":"intro.html","id":"download-loop","chapter":"2 Introduction","heading":"2.7 Download Loop","text":"next sections using county level employment/labor force data BLS learn working actual data. using Labor force data county, yearly annual averages. data 1990-2019 (writing notes). start going download data read R.can use loop download/clean data :work first let’s think trying achieve. links downloads form https://www.bls.gov/lau/laucntyZZ.xlsx, ZZ two digits representing year. ZZ values run “90”“99” years 1990-1999 “00” “19” years 2000-2019.Let’s work code line line:Lines #1 & #2: load required packages.Line #3: Declare unemp_data data.frame. Right now empty, add .Line #4: Define vector elements 90-99 0-19. (correspond years pull)Line #5 : vector years, however notice url names need vector include leading 0 front single ‘character’ digits (ie “01” instead “1”). don’t want leading 0 front double ‘character’ digits (ie DON’T want “090”). Go back String Manipulation section need refresh .Line #6 : Calculate length years save years_lLine #7 : See String Manipulation defining loop make sense.Line #8 : creating character string url download link. Since take form https://www.bls.gov/lau/laucntyZZ.xlsx, can use one element years vector time. (See String Manipulation explanation paste0)Line #9 : similar spirit line #4, defining path/filename excel file save.Line #10 : line just telling R download file url, save defined location/name, read non-raw text form. (see Downloading/Reading Data unclear.)Lines #11-#16: See Downloading/Reading Data direct explanation.Line #17: rbind appends data. Hence since data format variable indicating year, can simply append.Line #19: Create filepath (processed_data folder) save file, file name type .Line #20: save combined data location/name defined .now data cleaned saved next lesson start work !","code":"\nrequire(stringr)                                                                # 1\nrequire(readxl)                                                                 # 2\nunemp_data<-data.frame()                                                        # 3\nyears<-c(90:99, 0:19)                                                           # 4\nyears<-str_pad(as.character(years), 2, \"left\", \"0\")                             # 5\nyears_l<-length(years)                                                          # 6\nfor (i in 1:years_l){                                                           # 7\nurl<-paste0(\"https://www.bls.gov/lau/laucnty\", years[i], \".xlsx\")               # 8\ndestination<-paste0(folder_raw_data, \"/bls_unemp_\", years[i], \".xlsx\")          # 9\ndownload.file(url, destination, mode=\"wb\")                                     # 10\ntemp_df <- read_excel(paste0(folder_raw_data, \"/bls_unemp_\", years[i],         # 11\n  \".xlsx\"),col_names=FALSE, skip=5)                                            # 12\ntemp_df<-temp_df[,-6]                                                          # 13\ncolnames(temp_df)<-c(\"LAUS_code\", \"State_fips\", \"County_fips\", \"County_name\",  # 14\n  \"Year\", \"Labor_force\", \"Employed\", \"Unemployed\", \"Unemp_rate\")               # 15\ntemp_df<-temp_df[!is.na(temp_df$State_fips),]                                  # 16\nunemp_data<-rbind(county_data, temp_df)                                        # 17\n}                                                                              # 18\nfilename<-paste0(folder_processed_data, \"/unemp_data.rda\")                     # 19\nsave(unemp_data, file=filename)                                                # 20"},{"path":"tidyverse.html","id":"tidyverse","chapter":"3 Tidyverse","heading":"3 Tidyverse","text":"goal Tidyverse section learnSubsetting DatasetsMerging DatasetsSummarizingPlottingIn section continuing working BLS data downloaded Introduction.Tidyverse provides us useful tools data manipulation cleaning. include examples descriptions commands frequently used.","code":""},{"path":"tidyverse.html","id":"filtering-with-pipes","chapter":"3 Tidyverse","heading":"3.1 Filtering with Pipes","text":"going line code? Let’s start second line. operator %>% called pipe. comes package called magittr included within tidyverse. Pipes handy neatly writing longer sequences code. begin pretty simple example. can think pipes saying “.” takes argument uses input following command. using filter command, saying take data.frame county_data, filter “give us” values State_fips equal “18” (fips code Indiana. Go Hoosiers!). summary just filtering indiana data saving new data frame (line 1). Note: operation impact county_data, way ‘write’ data frame explicitly tell . example following overwrite county_data.","code":"\nindiana<-                                    # 1\n    unemp_data %>% filter(State_fips==\"18\")  # 2\nunemp_data<-unemp_data %>% filter(State_fips==\"18\")  # 1"},{"path":"tidyverse.html","id":"plotting-data","chapter":"3 Tidyverse","heading":"3.2 Plotting Data","text":"lesson plotting data gathered previous lessons. ggplot2 popular package plotting now included part tidyverse package. allows us make many different kinds plots customize . popular many guides . Tidyverse’s website summarizes useful resources.ggplot2 many options, just barely skimming surface introduction. Let’s start minimal command. First let’s load ggplot2 filter data just Indiana.Line #1: Tells ggplot using data.frame indiana. aes short aesthetics. tell ggplot map data plots. want ggplot plot Year x-axis, Unemp_rate y-axis.Line #2: continuation aesthetic mapping, line saying plot separately County_fips separately, giving different color.Line #3: Tells ggplot plot data lines.First thing plot, legend excessive. Let’s just suppress now. can define legend.position theme none. theme command allows lot customization plot. want see options click . Let’s also change thickness lines, can alpha argument.already looking lot better. can something labels x axis, overlaying . make text smaller difficult see, let’s just rotate . Also let’s make y-axis name bit meaningful.Now ’re getting somewhere! want emphasize county Bloomington , Monroe County?can make black line Monroe County ‘pop’ bit . Let’s change opacity counties lines. can set value, alpha. takes values 0 1 smaller values transparent.","code":"\nlibrary(ggplot2)                                    # 1\n                                                    # 2\nindiana <- unemp_data %>% filter(State_fips==\"18\")  # 3\nggplot(data=indiana, aes(x=Year, y=Unemp_rate,   # 1\n    colour=County_fips, group=County_fips))+     # 2\n  geom_line()                                    # 3\nggplot(data=indiana, aes(x=Year, y=Unemp_rate,   # 1\n    colour=County_fips, group=County_fips))+     # 2\n  geom_line(size=0.3)+                           # 3\n  theme(legend.position=\"none\")                  # 4\nggplot(data=indiana, aes(x=Year, y=Unemp_rate,   # 1\n    colour=County_fips, group=County_fips))+     # 2\n  geom_line(size=0.3)+                           # 3\n  theme(legend.position=\"none\",                  # 4\n    axis.text.x=element_text(angle=45)) +        # 5\n  ylab('Indiana Unemployment Rate by County')    # 6\nmonroecty<-indiana %>% filter(County_fips==\"105\")       # 1\n                                                        # 2\nggplot(data=indiana, aes(x=Year, y=Unemp_rate,          # 3\n    colour=County_fips, group=County_fips))+            # 4\n  geom_line(size=0.3)+                                  # 5\n  geom_line(data=monroecty, aes(x=Year, y=Unemp_rate,   # 6\n    colour=County_fips, group=1),                       # 7\n    size=0.6, colour='black') +                         # 8\n  theme(legend.position=\"none\",                         # 9\n    axis.text.x=element_text(angle=45)) +              # 10\n  ylab('Indiana Unemployment Rate by County')          # 11\nggplot(data=indiana, aes(x=Year, y=Unemp_rate,          # 1\n    colour=County_fips, group=County_fips))+            # 2\n  geom_line(size=0.3, alpha=0.5)+                       # 3\n  geom_line(data=monroecty, aes(x=Year, y=Unemp_rate,   # 4\n    colour=County_fips, group=1),                       # 5\n    size=0.6, colour='black') +                         # 6\n  theme(legend.position=\"none\",                         # 7\n    axis.text.x=element_text(angle=45)) +               # 8\n  ylab('Indiana Unemployment Rate by County')           # 9"},{"path":"tidyverse.html","id":"scatter-plot-geom_point","chapter":"3 Tidyverse","heading":"3.2.1 Scatter plot (geom_point)","text":"want points insteaed lines year?","code":"\nggplot(data=indiana, aes(x=Year, y=Unemp_rate,   # 1\n  colour=County_fips, group=County_fips))+       # 2\n  geom_point()                                   # 3"},{"path":"tidyverse.html","id":"manipulating-within-groups","chapter":"3 Tidyverse","heading":"3.3 Manipulating within Groups","text":"next chunk code gets bit complex, let’s take peice peice though.Let’s take end work ways backwards . 3rd line calculating new variable within group called ‘Average.’ group (line 2) calculating within Year Indiana data.frame. snippet code give us one value back year, average Labor Force level across Indiana’s counties.group_by command paired summarise quite useful. example going back original data.frame, county_data. Suppose wanted just states. calculate within state year combination. group_by command quite simple! (print first 100 lines output )Average just one statistic may want calculate, percentiles, minimum, maximum, standard deviation. summarise command accept one argument, just separate comma. Let’s also save new data.frame use future lessons.","code":"\n  indiana %>% group_by(Year) %>%          # 1\n    summarise(Average=mean(Labor_force))  # 2\nunemp_data %>%                          # 1\n  group_by(Year, State_fips) %>%        # 2\n  summarise(Average=mean(Labor_force))  # 3## `summarise()` has grouped output by 'Year'. You can override using the `.groups` argument.\nindiana_laborforce<-                       # 1\n  indiana %>% group_by(Year) %>%           # 2\n  summarise(Min=min(Labor_force),          # 3\n    p10th=quantile(Labor_force, c(0.1)),   # 4\n    p25th=quantile(Labor_force, c(0.25)),  # 5\n    p50th=quantile(Labor_force, c(0.5)),   # 6\n    p75th=quantile(Labor_force, c(0.75)),  # 7\n    p90th=quantile(Labor_force, c(0.9)),   # 8\n    Max=max(Labor_force),                  # 9\n    Average=mean(Labor_force),            # 10\n    StDev=sd(Labor_force))                # 11"},{"path":"tidyverse.html","id":"defining-new-variables","chapter":"3 Tidyverse","heading":"3.4 Defining New Variables","text":"don’t want calculate summary statistics within group, just want calculate new variable observation? Consider unemployed labor force levels unemployment rate, go calculating mutate?Note since defining new data frame indiana, one manipulating, case overwriting indiana data.frame. Since unemployment rate file listed percent rounded nearest tenth, calculated. (digits=1 means one decimal place)Now let’s compare first rows given unemployment rate one just calculated.","code":"\nindiana<-                                                                # 1\n  indiana %>%                                                            # 2\n  mutate(unemp_rate_calc=round((Unemployed/Labor_force)*100, digits=1))  # 3## # A tibble: 6 x 2\n##   Unemp_rate unemp_rate_calc\n##        <dbl>           <dbl>\n## 1        6.5             6.5\n## 2        5.1             5.1\n## 3        4.8             4.8\n## 4        3.4             3.4\n## 5        9.2             9.2\n## 6        2.4             2.4"},{"path":"tidyverse.html","id":"dropping-variables","chapter":"3 Tidyverse","heading":"3.5 Dropping Variables","text":"can go dropping keeping certain variables?Say wanted drop unemp_rate_calc, Labor_force, Employed?Now wanted keep just State_fips, County_fips, Year, Unemp_rate?include “-” variables, telling dplyr select argument drop variables list. don’t “-,” telling dplyr keep variables.","code":"\ntemp<-                                                 # 1\n  indiana %>%                                          # 2\n  select(-c(unemp_rate_calc, Labor_force,  Employed))  # 3\nhead(temp)                                             # 4## # A tibble: 6 x 7\n##   LAUS_code       State_fips County_fips County_name            Year  Unemployed Unemp_rate\n##   <chr>           <chr>      <chr>       <chr>                  <chr>      <dbl>      <dbl>\n## 1 CN1800100000000 18         001         Adams County, IN       1990         998        6.5\n## 2 CN1800300000000 18         003         Allen County, IN       1990        8317        5.1\n## 3 CN1800500000000 18         005         Bartholomew County, IN 1990        1632        4.8\n## 4 CN1800700000000 18         007         Benton County, IN      1990         156        3.4\n## 5 CN1800900000000 18         009         Blackford County, IN   1990         643        9.2\n## 6 CN1801100000000 18         011         Boone County, IN       1990         483        2.4\ntemp<-                                                  # 1\n  indiana %>%                                           # 2\n  select(c(State_fips, County_fips, Year, Unemp_rate))  # 3\nhead(temp)                                              # 4## # A tibble: 6 x 4\n##   State_fips County_fips Year  Unemp_rate\n##   <chr>      <chr>       <chr>      <dbl>\n## 1 18         001         1990         6.5\n## 2 18         003         1990         5.1\n## 3 18         005         1990         4.8\n## 4 18         007         1990         3.4\n## 5 18         009         1990         9.2\n## 6 18         011         1990         2.4"},{"path":"tidyverse.html","id":"merging-datasets","chapter":"3 Tidyverse","heading":"3.6 Merging Datasets","text":"2 data sets, county level. combine ?","code":""},{"path":"tidyverse.html","id":"poverty-estimates","chapter":"3 Tidyverse","heading":"3.6.1 Poverty Estimates","text":"merging poverty estimates US counties 2019. table prepared USDA can found website . Let’s download put original_data folder. Now let’s open see data looks like. One first things can notice first 2 lines, United States Alabama. county state level observations addition county level ones. need keep mind merge unemployment data.Try figure read data R . need review, go back Downloading/Reading Data. Remember using R Studio assist probably simplest way get comfortable commands.command use :Make sure also county unemployment data read . can observe data.frames now. way clean data following (course depends question/results trying obtain):unemployment data:\nrestrict 2019 data (county data just 2019)\nDrop Year variable (one year now)\nDrop Puerto Rico (State FIPS 72)\ncombine state_fips county_fips FIPStxt variable (variable poverty data later using ID merge data .)\nrestrict 2019 data (county data just 2019)Drop Year variable (one year now)Drop Puerto Rico (State FIPS 72)combine state_fips county_fips FIPStxt variable (variable poverty data later using ID merge data .)poverty data:\nfilter state/country level observations, leaving just county level.\nfilter state/country level observations, leaving just county level.code use :Now observe data frames left want merge. defined variable FIPStxt like join observations . given FIPStxt ID unemployment data, like find row FIPStxt ID poverty data, add variables poverty data unemployment data. iterations FIPStxt ID.join commands dplyr package. clearest join command full_join. matches data frames based common variable names (defined variable names match .) print first 3 rows .","code":"\nPovertyEstimates <-                                             # 1\n  read_excel(paste0(folder_raw_data, \"/PovertyEstimates.xls\"),  # 2\n  skip = 4)                                                     # 3\nunem_2019<-county_data %>%                                                            # 1\n  filter(Year==2019, State_fips!=72) %>% #restrict sample to only year 2019, drop PR  # 2\n  select(-Year) %>% #drop the variable Year                                           # 3\n  mutate(FIPStxt=paste0(State_fips, County_fips)) #Create variable to merge on        # 4\n                                                                                      # 5\npov_2019 <- PovertyEstimates %>%                                                      # 6\n  filter(substr(FIPStxt, str_length(FIPStxt)-2, str_length(FIPStxt))!=\"000\")          # 7\nclean_full<-                         # 1\n  unem_2019 %>% full_join(pov_2019)  # 2## Joining, by = \"FIPStxt\""},{"path":"tidyverse.html","id":"left_join","chapter":"3 Tidyverse","heading":"3.6.2 left_join","text":"full_join command probably ‘safest’ route since prints variables rows data frames, knowing joins can save us time.example, consider first loaded poverty data. observations state country wide levels addition county level data wanted. ideally want command took county unemployment data, matched poverty data based FIPStxt, just exclude extras poverty data. can left (right) join.case starting unemployment data, telling R match possible values common variable (FIPStxt ), don’t care poverty estimate observations can’t matched. However unemployment observations can’t ? simply fill values NA’s. example, DON’T exclude Puerto Rico, unemployment data, poverty data. Let’s see happens:","code":"\nunclean_left<-                               # 1\n  unem_2019 %>% left_join(PovertyEstimates)  # 2## Joining, by = \"FIPStxt\"\nunem_2019_pr<-county_data %>%                      # 1\n  filter(Year==2019) %>%                           # 2\n  select(-Year) %>%                                # 3\n  mutate(FIPStxt=paste0(State_fips, County_fips))  # 4\npr<-                                               # 5\n  unem_2019_pr %>%                                 # 6\n  left_join(PovertyEstimates) %>%                  # 7\n  filter(State_fips==72)                           # 8## Joining, by = \"FIPStxt\""},{"path":"tidyverse.html","id":"additional-resources","chapter":"3 Tidyverse","heading":"3.6.3 Additional Resources","text":"addition full left join shown , also inner join right join. Details can found .","code":""},{"path":"exporting.html","id":"exporting","chapter":"4 Exporting Results","heading":"4 Exporting Results","text":"goal section learn take figures/tables created tidyverse section export directly form can read LaTex.Specifically:Xtableggsave","code":""},{"path":"exporting.html","id":"saving-plots","chapter":"4 Exporting Results","heading":"4.1 Saving Plots","text":"See ggplot section tidyverse section previously learn generate plot. generated plot like, let’s save .use ggsave command.take last graphic memory save location specify. can also tell ggplot make plot specific dimensions highly recommend . specify dimensions, can dependent size viewer RStudio.","code":"\nggsave(file=paste0(folder_figures, \"/indiana_unemp.png\"))      # 1\nggsave(file=paste0(folder_figures, \"/indiana_unemp.png\"),   # 1\n  height = 5, width = 7)                                    # 2"},{"path":"exporting.html","id":"tables-to-latex","chapter":"4 Exporting Results","heading":"4.2 Tables to LaTex","text":"Let’s learn export summary table created dplyr section. Just review created .Now let’s load package xtable. package allows us print data.frames tex table environment. Let’s first inspect output just running base function minimal options.copy paste output latex. However, can tell xtable R save tex file . Notice pathing used. latex table keeping organized 1) giving tex file useful name 2) saving within tables folder. may seem extra tedious now come generating hundreds plots tables, organazation can key keeping everything straight.Try building table pdf LaTexLet’s now customize table . First, let’s get rid row names meaningful us . Also, want later fix table certain place tex document want table placement H.Let’s add bit customization table.Line #4: Round digits nearest integer.Line #5: add label table can reference main tex document.Line #6: want custom alignment table. (Note: command requires 1 column arguments columns table. due printing row names. However later define include.rownames FALSE . get rid first column row names.)many packages can assist creating tex tables. later use stargazer reporting regression results. like using xtable due ’s ease customize. Please leave note favorite packages creating tex tables.","code":"\nindiana_laborforce<-                       # 1   # 1\n  unemp_data %>%                           # 2   # 2\n  filter(State_fips==\"18\") %>%             # 3   # 3\n  group_by(Year) %>%                       # 4   # 4\n  summarise(Min=min(Labor_force),          # 5   # 5\n    p10th=quantile(Labor_force, c(0.1)),   # 6   # 6\n    p25th=quantile(Labor_force, c(0.25)),  # 7   # 7\n    p50th=quantile(Labor_force, c(0.5)),   # 8   # 8\n    p75th=quantile(Labor_force, c(0.75)),  # 9   # 9\n    p90th=quantile(Labor_force, c(0.9)),  # 10  # 10\n    Max=max(Labor_force),                 # 11  # 11\n    Average=mean(Labor_force),            # 12  # 12\n    StDev=sd(Labor_force))                # 13  # 13\n  xtable(indiana_laborforce)  # 1  # 1## % latex table generated in R 4.1.1 by xtable 1.8-4 package\n## % Sat Jan 01 17:21:37 2022\n## \\begin{table}[ht]\n## \\centering\n## \\begin{tabular}{rlrrrrrrrrr}\n##   \\hline\n##  & Year & Min & p10th & p25th & p50th & p75th & p90th & Max & Average & StDev \\\\ \n##   \\hline\n## 1 & 1990 & 2629.00 & 6639.30 & 9617.50 & 14858.50 & 30089.50 & 60784.50 & 424053.00 & 30593.65 & 52989.19 \\\\ \n##   2 & 1991 & 2541.00 & 6380.50 & 9480.00 & 14713.00 & 30131.00 & 62309.90 & 421789.00 & 30357.00 & 52670.08 \\\\ \n##   3 & 1992 & 2550.00 & 6284.20 & 9615.50 & 15169.50 & 31117.00 & 63623.20 & 429239.00 & 31058.60 & 53551.02 \\\\ \n##   4 & 1993 & 2607.00 & 6200.60 & 10037.75 & 15652.50 & 32034.75 & 64549.90 & 438377.00 & 32046.84 & 54683.97 \\\\ \n##   5 & 1994 & 2681.00 & 6453.10 & 10480.50 & 16472.00 & 33808.25 & 66506.30 & 453457.00 & 33308.01 & 56427.35 \\\\ \n##   6 & 1995 & 2714.00 & 6543.20 & 10994.75 & 16648.50 & 34588.00 & 67364.50 & 459603.00 & 34078.00 & 57219.27 \\\\ \n##   7 & 1996 & 2724.00 & 6522.60 & 10827.50 & 16551.00 & 34597.25 & 66487.50 & 453728.00 & 33800.80 & 56670.37 \\\\ \n##   8 & 1997 & 2698.00 & 6585.30 & 10966.00 & 16671.50 & 34786.50 & 66195.30 & 453928.00 & 33919.72 & 56870.28 \\\\ \n##   9 & 1998 & 2701.00 & 6629.70 & 11008.75 & 16660.00 & 34150.50 & 65887.60 & 452412.00 & 33947.47 & 56827.82 \\\\ \n##   10 & 1999 & 2691.00 & 6496.70 & 10986.75 & 16958.50 & 33968.50 & 65196.00 & 448732.00 & 33965.91 & 56434.89 \\\\ \n##   11 & 2000 & 2985.00 & 7053.50 & 10816.50 & 16984.50 & 34996.50 & 63718.60 & 455135.00 & 33982.50 & 56818.02 \\\\ \n##   12 & 2001 & 2982.00 & 7085.70 & 10709.00 & 17127.50 & 34674.75 & 64832.00 & 459505.00 & 34140.32 & 57318.59 \\\\ \n##   13 & 2002 & 3051.00 & 7040.70 & 10802.75 & 17244.50 & 34974.75 & 66572.30 & 462330.00 & 34469.34 & 57807.67 \\\\ \n##   14 & 2003 & 3092.00 & 6941.00 & 10709.50 & 17199.00 & 34514.75 & 67751.50 & 464331.00 & 34597.76 & 58056.22 \\\\ \n##   15 & 2004 & 3109.00 & 6815.20 & 10547.00 & 17083.50 & 33431.50 & 68476.20 & 459140.00 & 34432.72 & 57583.09 \\\\ \n##   16 & 2005 & 3152.00 & 7075.80 & 10702.75 & 17357.50 & 33606.00 & 69985.60 & 459492.00 & 34841.75 & 57925.42 \\\\ \n##   17 & 2006 & 3107.00 & 6883.10 & 10620.50 & 17326.50 & 34554.50 & 72792.00 & 461468.00 & 35164.35 & 58484.53 \\\\ \n##   18 & 2007 & 3026.00 & 6816.70 & 10447.50 & 16881.00 & 34304.50 & 73128.10 & 460046.00 & 34866.21 & 58342.88 \\\\ \n##   19 & 2008 & 3044.00 & 6816.20 & 10488.00 & 16673.50 & 34065.50 & 75072.00 & 463200.00 & 35131.49 & 58819.13 \\\\ \n##   20 & 2009 & 3088.00 & 6758.40 & 10434.25 & 16452.00 & 33700.25 & 74434.10 & 457524.00 & 34717.45 & 58083.80 \\\\ \n##   21 & 2010 & 3263.00 & 6440.50 & 10308.00 & 16622.00 & 33921.75 & 74406.00 & 452836.00 & 34512.97 & 57806.16 \\\\ \n##   22 & 2011 & 3210.00 & 6459.90 & 10184.25 & 16630.50 & 33804.00 & 75620.50 & 456011.00 & 34586.91 & 58199.53 \\\\ \n##   23 & 2012 & 3181.00 & 6336.20 & 10058.50 & 16453.00 & 32924.00 & 76458.00 & 458377.00 & 34454.88 & 58388.80 \\\\ \n##   24 & 2013 & 3165.00 & 6325.90 & 9900.50 & 16289.50 & 33053.00 & 78149.50 & 463346.00 & 34656.59 & 58983.65 \\\\ \n##   25 & 2014 & 3216.00 & 6401.20 & 9851.50 & 16524.00 & 33215.50 & 80113.30 & 467169.00 & 35052.00 & 59579.47 \\\\ \n##   26 & 2015 & 3178.00 & 6341.80 & 9924.75 & 16908.00 & 33960.00 & 82327.70 & 472330.00 & 35508.30 & 60275.44 \\\\ \n##   27 & 2016 & 3226.00 & 6444.80 & 9930.50 & 17093.50 & 35149.00 & 85223.00 & 481434.00 & 36178.11 & 61517.07 \\\\ \n##   28 & 2017 & 3153.00 & 6512.50 & 9783.75 & 17119.00 & 35516.50 & 85487.60 & 483607.00 & 36243.96 & 61840.36 \\\\ \n##   29 & 2018 & 3189.00 & 6561.90 & 9943.50 & 17334.50 & 36211.00 & 86905.80 & 488698.00 & 36756.59 & 62659.34 \\\\ \n##   30 & 2019 & 3201.00 & 6615.60 & 9812.75 & 17243.00 & 36470.50 & 87146.90 & 492967.00 & 36819.25 & 63114.77 \\\\ \n##    \\hline\n## \\end{tabular}\n## \\end{table}\n  print.xtable(                                                # 1  # 1\n    xtable(indiana_laborforce),                                # 2  # 2\n    file=paste0(workingdir, \"tables/indiana_laborforce.tex\"))  # 3  # 3\nprint.xtable(                                                 # 1  # 1\n  xtable(indiana_laborforce),                                 # 2  # 2\n  table.placement=\"H\",                                        # 3  # 3\n  include.rownames=FALSE,                                     # 4  # 4\n  file=paste0(workingdir, \"tables/indiana_laborforce.tex\"),   # 5  # 5\n  )                                                           # 6  # 6\nprint.xtable(                                                     # 1  # 1\n  xtable(                                                         # 2  # 2\n  indiana_laborforce,                                             # 3  # 3\n  digits=0,                                                       # 4  # 4\n  label= \"tab:indiana_laborforce\",                                # 5  # 5\n  align = c(\"|c|\",\"|c|\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c|\")),   # 6  # 6\n  table.placement=\"H\",                                            # 7  # 7\n  include.rownames=FALSE,                                         # 8  # 8\n  file=paste0(folder_tables, \"/indiana_laborforce.tex\"))          # 9  # 9"},{"path":"GIS.html","id":"GIS","chapter":"5 GIS Example","heading":"5 GIS Example","text":"chapter looks GIS work research project progress. investigate question whether politician’s margin victory related pollution outcomes assemble dataset combining data EPA pollution monitors, election results, congressional district boundaries, county level variables, weather data matching together geography","code":""},{"path":"GIS.html","id":"mit-election-data","chapter":"5 GIS Example","heading":"5.1 MIT Election Data","text":"Data U.S. House elections 1976-2016 obtained MIT’s Election Data Science Lab. data contains name candidates running US House election, state district running , party affiliation, write candidate, many votes received, many votes cast election overall, election special regular election.data allows define incumbency variables grouping incumbents number terms served. Since data spans back 1976, incumbency measure based 1976 starting point. Thus wanted group incumbents serving 3 terms, check politicians served three previous terms. example, 1980 see given victorious politician also won elections 1976 1978. categorize 3 term Representative. want group 5 term incumbents, able 1980 since need data going back 1972. cases analysis drop pollution observations beginning sample reason.also calculate margin victory data defined difference votes top two candidates divided sum top two. example consider race three candidates, Republican victor 45% vote, Democrat wins 40% vote, Independent wins remaining 15% vote. Calculating margin victory give us:\\[\n\\frac{0.45 - 0.40}{0.45 + 0.40} \\approx 0.0588\n\\]Results elections matched pollution monitors mapping monitors congressional districts attributing monitors districts politicians represent. Historic district boundary shapefiles obtained website Lewis et al (2013). maps allow overlay pollution monitor’s latitude longitude coordinates, obtaining district monitor located. Example boundaries 110th congress (contiguous US) .","code":""},{"path":"GIS.html","id":"pollution-data","chapter":"5 GIS Example","heading":"5.2 Pollution Data","text":"Ozone pollution data obtained EPA’s website Air Quality daily frequency. Monitors collect observations course day parts per million ground level ozone, averaged consecutive 8-hour readings. utilize maximum 8-hour reading day, restricting sample reliable monitors within month defined 25 day readings within July. average top 5 days within month July. illustrate percentiles.","code":""},{"path":"GIS.html","id":"bls-county-statistics","chapter":"5 GIS Example","heading":"5.3 BLS County Statistics","text":"Data yearly population, personal income, employment data county level obtained Bureau Economic Analysis. Utilizing data combination county shapefiles Census Bureau allowed calculate population density county.","code":""},{"path":"GIS.html","id":"combining-data","chapter":"5 GIS Example","heading":"5.4 Combining Data","text":"Pollution monitors point space congressional districts counties area. Hence map points boundaries. image illustrate : colored areas represent counties, dark boundaries represent congressional districts, points pollution monitor locations.","code":""}]
